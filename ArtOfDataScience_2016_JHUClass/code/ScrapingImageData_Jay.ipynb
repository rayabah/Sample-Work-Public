{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with image data from viz.neurodata\n",
    "\n",
    "### preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    19   1369     55   5063      0]\n",
      " [    58   2851   1165      0      0]\n",
      " [   136   2344   1054   3042      0]\n",
      " [   214   1837    943   3224      0]\n",
      " [   253   3358    832      0      0]\n",
      " [   331   2851    721  82193     87]\n",
      " [   409   2344    610 118055    147]\n",
      " [   487   1837    499 153461    205]\n",
      " [   526   3358    388      0      0]\n",
      " [   604   2851    277  61430     20]\n",
      " [   682   2344    166 132042    177]\n",
      " [   760   1837     55 153350    177]\n",
      " [   799   3319   1165  15316      7]\n",
      " [   877   2812   1054 152682    194]\n",
      " [   955   2305    943 138771    286]\n",
      " [  1033   1798    832 134847    186]\n",
      " [  1072   3319    721      0      0]\n",
      " [  1150   2812    610 126243    115]\n",
      " [  1228   2305    499 150331    178]\n",
      " [  1306   1798    388 150579    263]\n",
      " [  1345   3319    277      0      0]\n",
      " [  1423   2812    166 134814     83]\n",
      " [  1501   2305     55 133161    132]\n",
      " [  1579   1759   1165 159705    207]\n",
      " [  1618   3280   1054   5186      0]\n",
      " [  1696   2773    943 152424    120]\n",
      " [  1774   2266    832  57804     36]\n",
      " [  1852   1759    721 147498    206]\n",
      " [  1891   3280    610      0      0]\n",
      " [  1969   2773    499 158184    234]\n",
      " [  2047   2266    388 147637    183]\n",
      " [  2125   1759    277  32607     19]\n",
      " [  2164   3280    166      0      0]\n",
      " [  2242   2773     55 151533    164]\n",
      " [  2320   2227   1165 157801    156]\n",
      " [  2398   1720   1054 164268    231]\n",
      " [  2437   3241    943   2390      0]\n",
      " [  2515   2734    832 147526    197]\n",
      " [  2593   2227    721 144017    161]\n",
      " [  2671   1720    610 140025    108]\n",
      " [  2710   3241    499      0      0]\n",
      " [  2788   2734    388 105144     76]\n",
      " [  2866   2227    277 155142    226]\n",
      " [  2944   1720    166 137611    195]\n",
      " [  2983   3241     55      0      0]\n",
      " [  3061   2695   1165 156632    143]\n",
      " [  3139   2188   1054 161226    216]\n",
      " [  3217   1681    943 156828    251]\n",
      " [  3256   3202    832   1426      0]\n",
      " [  3334   2695    721 147537    173]\n",
      " [  3412   2188    610 130806    192]\n",
      " [  3490   1681    499 116872    223]\n",
      " [  3529   3202    388      0      0]\n",
      " [  3607   2695    277 150520    214]\n",
      " [  3685   2188    166 136854    176]\n",
      " [  3763   1681     55 100042     83]\n",
      " [  3802   3163   1165      0      0]\n",
      " [  3880   2656   1054     49      0]\n",
      " [  3958   2149    943  12275      1]\n",
      " [  4036   1642    832  11478      9]\n",
      " [  4075   3163    721      0      0]\n",
      " [  4153   2656    610  10647      3]]\n",
      "165789\n",
      "[108, 52, 11]\n",
      "[(4192, 19), (3358, 1369), (1165, 55)]\n",
      "[4173, 1989, 1110]\n",
      "x-axis: \n",
      "unique bins (in data):  108\n",
      "[  19   58   97  136  175  214  253  292  331  370  409  448  487  526  565\n",
      "  604  643  682  721  760  799  838  877  916  955  994 1033 1072 1111 1150\n",
      " 1189 1228 1267 1306 1345 1384 1423 1462 1501 1540 1579 1618 1657 1696 1735\n",
      " 1774 1813 1852 1891 1930 1969 2008 2047 2086 2125 2164 2203 2242 2281 2320\n",
      " 2359 2398 2437 2476 2515 2554 2593 2632 2671 2710 2749 2788 2827 2866 2905\n",
      " 2944 2983 3022 3061 3100 3139 3178 3217 3256 3295 3334 3373 3412 3451 3490\n",
      " 3529 3568 3607 3646 3685 3724 3763 3802 3841 3880 3919 3958 3997 4036 4075\n",
      " 4114 4153 4192]\n",
      "\n",
      "y-axis: \n",
      "unique bins (in data):  52\n",
      "[1369 1408 1447 1486 1525 1564 1603 1642 1681 1720 1759 1798 1837 1876 1915\n",
      " 1954 1993 2032 2071 2110 2149 2188 2227 2266 2305 2344 2383 2422 2461 2500\n",
      " 2539 2578 2617 2656 2695 2734 2773 2812 2851 2890 2929 2968 3007 3046 3085\n",
      " 3124 3163 3202 3241 3280 3319 3358]\n",
      "\n",
      "z-axis: \n",
      "unique bins (in data):  11\n",
      "[  55  166  277  388  499  610  721  832  943 1054 1165]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import urllib2\n",
    "from __future__ import division\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(1)\n",
    "url = ('https://raw.githubusercontent.com/Upward-Spiral-Science'\n",
    "       '/data/master/syn-density/output.csv')\n",
    "data = urllib2.urlopen(url)\n",
    "csv = np.genfromtxt(data, delimiter=\",\",dtype='int')[1:] # don't want first row (labels)\n",
    "data = csv\n",
    "print data[::1000]\n",
    "sizes = [len(np.unique(data[:, i])) for i in range(3)]\n",
    "ranges = [(np.max(data[:, i]), np.min(data[:,i])) for i in range(3)]\n",
    "ranges_diff = [np.max(data[:, i])-np.min(data[:,i]) for i in range(3)]\n",
    "print np.max(data[:,3])\n",
    "print sizes\n",
    "print ranges\n",
    "print ranges_diff\n",
    "for i, ax in zip(range(3), ['x', 'y', 'z']):\n",
    "    print ax + '-axis: '\n",
    "    print 'unique bins (in data): ', np.unique(data[:, i]).size\n",
    "    print np.unique(data[:, i])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using image data\n",
    "### Where's the origin (xy-plane)? See blue marker (y axis points down)\n",
    "<img style=\"width:300px\" src=\"origin.png\">\n",
    "### converting from data units (cx, cy, cz) to pixels \n",
    "From the data given, it seems that in the x-direction, we have 108 bins, and in the y-direction, 86. Further support for this claim: 108/85 ~= 450/350; 450x350 the stated dimensions (Âµm) in Bock 2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253.92592593 1393.11627907\n"
     ]
    }
   ],
   "source": [
    "xPix = 135424\n",
    "yPix = 119808\n",
    "xPixPerBin = xPix/108.0\n",
    "yPixPerBin = yPix/86.0\n",
    "print xPixPerBin, yPixPerBin\n",
    "# Now since each bin is 40 data coordinates we can define the following function to convert from coordinates to pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134780.96106362774, 119950.88372093023)\n",
      "(1253.9259259259259, 1393.1162790697674)\n"
     ]
    }
   ],
   "source": [
    "def coords_to_px(xcoord, ycoord):\n",
    "    c_vec = np.array([xcoord, ycoord], dtype='float')\n",
    "    c_vec /= 39.0\n",
    "    return (c_vec[0]*xPixPerBin, c_vec[1]*yPixPerBin)\n",
    "\n",
    "# check that max coordinate values are close to max pixels\n",
    "print coords_to_px(4192, 3358)\n",
    "# how big is a bin? (just a sanity check, should obviously \n",
    "# be identical to xPixPerBin and yPixPerBin)\n",
    "print coords_to_px(39.0, 39.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing images from website\n",
    "Looking through the JavaScript code on viz.neurodata.io, we see that its tiling with 512x512 .png images. At resolution 0, each image has 512x512 \"pixels\" (correspdonding to the brain images) in it. This can be seen b/c total tiles in the x_direction is 264, and 264x512=135168, approximately our max pixels, and for y-direction, max tiles is 233, 233x512=119296, approximately the max pixels. Similarly for resolution 1, each 512x512 pmg now holds 1024x1024 \"pixels\", and so on as resolution goes up. Also note that at resolution 1, a single tile is very close in size to a single bin (looking at the second line of output of the previous code block, we see that bins are *slightly* larger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/2917/139_125_0.png\n"
     ]
    }
   ],
   "source": [
    "def get_tilenums_at_res(xcoord, ycoord, res):\n",
    "    x, y = coords_to_px(xcoord, ycoord)\n",
    "    x = np.floor(float(x)/(512*(2**res)))\n",
    "    y = np.floor(float(y)/(512*(2**res)))\n",
    "    return x,y\n",
    "\n",
    "def get_image_url1(xcoord, ycoord, res, z):\n",
    "    x, y = get_tilenums_at_res(xcoord, ycoord, res)\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    end = '/'+reduce(lambda x, y: str(x) +'_'+str(y), [y, x, res])\n",
    "    end += '.png'\n",
    "    imgurl = 'http://openconnecto.me/ocp/catmaid/bock11/image/xy/'+str(z) +end\n",
    "    return imgurl\n",
    "\n",
    "print get_image_url1(2000, 2000, 0, 2917)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just need to figure out z-axis. The z values in the image data go from 2917-4156, which is a range of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1239\n"
     ]
    }
   ],
   "source": [
    "print (2917-4156)*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the z-values in the data correspond approximately to the z-values in the image data, other than a translation of 2917. So let's redefine our function, and put it in one code block so its easy for other people to use..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: you can copy just this block into your notebook to use the get_image_url() function \n",
    "\n",
    "xPix = 135424\n",
    "yPix = 119808\n",
    "xPixPerBin = xPix/108.0\n",
    "yPixPerBin = yPix/86.0\n",
    "max_tiles_x = 264 # found via inspection of viz html/JS code\n",
    "max_tiles_y = 233 # found via inspection of viz html/JS code\n",
    "\n",
    "def coords_to_px(xcoord, ycoord):\n",
    "    c_vec = np.array([xcoord, ycoord], dtype='float')\n",
    "    c_vec /= 39.0\n",
    "    return (c_vec[0]*xPixPerBin, c_vec[1]*yPixPerBin)\n",
    "\n",
    "def get_tilenums_at_res(xcoord, ycoord, res):\n",
    "    x, y = coords_to_px(xcoord, ycoord)\n",
    "    if(res == 0):\n",
    "        x = np.round(float(x)/512)\n",
    "        y = np.round(float(y)/512)\n",
    "    else:\n",
    "        x = np.round(float(x)/(512*(2**res)))\n",
    "        y = np.round(float(y)/(512*(2**res)))\n",
    "    return x,y\n",
    "\n",
    "def get_image_url(xcoord, ycoord, zcoord, res=1):\n",
    "    \"\"\"\n",
    "    params: \n",
    "    - xcoord, ycoord, zcoord all in terms of coordinates in original data file\n",
    "    - res = image resolution, default = 1 \n",
    "        since 1024x1024 pixels, approx. the size of a bin--i think\n",
    "    returns: (string) url of image\n",
    "    \"\"\"\n",
    "    zcoord += 2917\n",
    "    z = int(zcoord)\n",
    "    x, y = get_tilenums_at_res(int(xcoord), int(ycoord), res)\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    if(x > max_tiles_x//(2**res)): x = max_tiles_x//(2**res)\n",
    "    if(y > max_tiles_y//(2**res)): y = max_tiles_y//(2**res)\n",
    "    end = '/' + reduce(lambda x, y: str(x) +'_'+str(y), [y, x, res])\n",
    "    end += '.png'\n",
    "    imgurl = 'http://openconnecto.me/ocp/catmaid/bock11/image/xy/' + str(z)\n",
    "    return imgurl+end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the image scraper w/ some exploratory questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/131_173_0.png\n",
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/65_86_1.png\n",
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/33_43_2.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/131_173_0.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/65_86_1.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/33_43_2.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML, display\n",
    "\n",
    "disp_dim = {'width': 200, 'height': 200} # just for quickly setting image width/height\n",
    "m = np.max(data[:, -1])\n",
    "a = np.where(data[:, -1]==m)\n",
    "args = list(*data[a, (0, 1, 2)])+[0]\n",
    "imgs = []\n",
    "for r in range(3):\n",
    "    args[-1] = r\n",
    "    u = get_image_url(*args)\n",
    "    print u\n",
    "    imgs.append(Image(url=u, **disp_dim))\n",
    "\n",
    "display(*imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above *should* be images of the bin where maximal number of synapses occured. Note changes in resolution let us zoom in and out.\n",
    "\n",
    "### What do high density and low density regions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010395174988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/2972/48_1_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3083/105_96_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3194/104_96_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/116_95_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/116_95_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3860/113_95_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3749/112_95_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3638/110_95_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3416/109_95_1.png' /><br> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/80_121_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3860/94_121_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/91_118_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/65_86_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3860/108_116_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/61_124_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3638/78_56_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3194/53_90_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3860/104_119_1.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dens_data = np.copy(data).astype(float)\n",
    "dens_data = dens_data[np.where(dens_data[:,3] != 0)]\n",
    "dens_data[:, 3] = dens_data[:, 4]/dens_data[:, 3]\n",
    "dens_data = dens_data[:,:-1]\n",
    "print np.average(dens_data[:,-1])\n",
    "a = np.argsort(dens_data[:, -1])\n",
    "urlsMin, urlsMax = zip(*[(get_image_url(*dens_data[a[i],:-1]),\n",
    "                          get_image_url(*dens_data[a[-1-i],:-1]))  \n",
    "                         for i in range(9)])\n",
    "tagsMin = ''.join([\"<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='%s' />\" % str(u) \n",
    "                     for u in urlsMin ])\n",
    "tagsMin += '<br> <br>'\n",
    "tagsMax = ''.join([\"<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='%s' />\" % str(u) \n",
    "                     for u in urlsMax ])\n",
    "display(HTML(tagsMin))\n",
    "display(HTML(tagsMax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black regions most likely are masked regions, thus it is actually not surprising too see large amounts of masked for both high and low density areas (since low unmasked increases density, but at the same time lowers synaptic probability). Furthermore, note that the data is binned across many z-slices, while here, we are only looking at one z-slice at a time, thus it is plausible for a high density bin to have an entire slice masked. This also indicates that it would be beneficial to write a function that computes pixel-wise average across z-slices for a bin and returns the corresponding image. We can also only look at the more 'cleaned' data, as many boundary points are likely to be picked up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00115002980202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/2972/108_81_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3083/106_57_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3305/106_67_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3305/108_67_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3416/109_67_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3305/108_13_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3194/108_13_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3083/108_13_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3194/105_68_1.png' /><br> <br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/65_86_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3638/78_56_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3638/76_83_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/94_54_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3305/95_77_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3083/87_97_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/2972/106_56_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3860/61_50_1.png' /><img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/74_111_1.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the clean data\n",
    "x_bounds = (409, 3529)\n",
    "y_bounds = (1564, 3124)\n",
    "\n",
    "def check_in_bounds(row, x_bounds, y_bounds):\n",
    "    if row[0] < x_bounds[0] or row[0] > x_bounds[1]:\n",
    "        return False\n",
    "    if row[1] < y_bounds[0] or row[1] > y_bounds[1]:\n",
    "        return False\n",
    "    if row[3] == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "indices_in_bound, = np.where(np.apply_along_axis(check_in_bounds, 1, csv, x_bounds, y_bounds))\n",
    "data_clean = csv[indices_in_bound]\n",
    "\n",
    "dens_data = np.copy(data_clean).astype(float)\n",
    "dens_data = dens_data[np.where(dens_data[:,3] != 0)]\n",
    "dens_data[:, 3] = dens_data[:, 4]/dens_data[:, 3]\n",
    "dens_data = dens_data[:,:-1]\n",
    "print np.average(dens_data[:,-1])\n",
    "a = np.argsort(dens_data[:, -1])\n",
    "urlsMin, urlsMax = zip(*[(get_image_url(*dens_data[a[i],:-1]),\n",
    "                          get_image_url(*dens_data[a[-1-i],:-1]))  \n",
    "                         for i in range(9)])\n",
    "tagsMin = ''.join([\"<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='%s' />\" % str(u) \n",
    "                     for u in urlsMin ])\n",
    "tagsMin += '<br> <br>'\n",
    "tagsMax = ''.join([\"<img style='width: 80px; margin: 0px; padding-right: 3px; float: left;' src='%s' />\" % str(u) \n",
    "                     for u in urlsMax ])\n",
    "display(HTML(tagsMin))\n",
    "display(HTML(tagsMax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about regions with high unmasked, and low synapses, and high unmasked with high synapses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[   838   2695   1054 107245      9]\n",
      "507\n",
      "507\n",
      "[  2749   1876   1054 149991    507]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/94_26_1.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/65_86_1.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "avg_unmasked = np.average(data[:,3])\n",
    "high_unmasked = data[np.where(data[:,3] > avg_unmasked)]\n",
    "\n",
    "low_synapses = []\n",
    "for s in count():\n",
    "    low_synapses = high_unmasked[np.where(high_unmasked[:,-1]==s)]\n",
    "    if low_synapses.size > 0:\n",
    "        print s\n",
    "        break\n",
    "d_low = low_synapses[0]\n",
    "print d_low\n",
    "imgs = []\n",
    "imgs.append(Image(url=get_image_url(*d_low[:3]), **disp_dim))\n",
    "max_s = np.max(data[:, 4])\n",
    "print max_s\n",
    "high_synapses = []\n",
    "for s in range(max_s, 0, -1):\n",
    "    high_synapses = high_unmasked[np.where(high_unmasked[:,-1]==s)]\n",
    "    if high_unmasked.size > 0:\n",
    "        print s\n",
    "        break\n",
    "d_high = high_synapses[0]\n",
    "print d_high\n",
    "imgs.append(Image(url=get_image_url(*d_high[:3]), **disp_dim))\n",
    "display(*imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/188_53_0.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3971/131_173_0.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# zoom in a resolution\n",
    "display(Image(url=get_image_url(*d_low[:3], res=0), **disp_dim), \n",
    "        Image(url=get_image_url(*d_high[:3], res=0), **disp_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A significant number of the bins were cut off below a given threshold on the y-axis before the data was given to us... What does that line look like?\n",
    "\n",
    "Since it appears that the coordinates in our data correspond to the center of a bin, we can see that there was no cut applied on the x-axis, since data starts at 19 and bin \"length\" is 40, and similarly no cut along z since data starts at 55 and bin \"depth\" is 110. But along the y-axis data starts at 1369; floor(1369/40)=34, meaning the first 34 bins along the y-axis was cut across all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2105.5 1369 610.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/24_33_2.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fairly arbitrarily, look at midpoint for x and z\n",
    "midx, midz = [np.median(np.unique(data[:, i])) for i in [0,2]]\n",
    "y = np.min(data[:, 1])\n",
    "print midx, y, midz\n",
    "Image(url=get_image_url(midx, y, midz, 2), **disp_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_0_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_1_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_2_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_3_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_4_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_5_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_6_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_7_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_8_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_9_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_10_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_11_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_12_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_13_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_14_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_15_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_16_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_17_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_18_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_19_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_20_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_21_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_22_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_23_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_24_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_25_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_26_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_27_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_28_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_29_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_30_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_31_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_32_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/12_33_3.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_0_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_1_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_2_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_3_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_4_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_5_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_6_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_7_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_8_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_9_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_10_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_11_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_12_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_13_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_14_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_15_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_16_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_17_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_18_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_19_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_20_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_21_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_22_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_23_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_24_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_25_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_26_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_27_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_28_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_29_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_30_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_31_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_32_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/3527/3_33_3.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nothing apparently notable, lets view across entire x-axis\n",
    "from itertools import groupby\n",
    "\n",
    "urls = [k for k,_ in groupby(\n",
    "        [get_image_url(x, y, midz, 3) \n",
    "         for x in np.sort(np.unique(data[:, 0]))])]\n",
    "imgTags = ''.join( [\"<img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='%s' />\" % str(u) \n",
    "                     for u in urls ])\n",
    "display(HTML(imgTags))\n",
    "\n",
    "# y value below cutoff\n",
    "urls = [k for k,_ in groupby(\n",
    "        [get_image_url(x, 39*10, midz, 3) \n",
    "         for x in np.sort(np.unique(data[:, 0]))])]\n",
    "imgTags = ''.join( [\"<img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='%s' />\" % str(u) \n",
    "                     for u in urls ])\n",
    "display(HTML(imgTags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First row shows where the data was sliced, second is somewhere before it was sliced (that is, data not included in the set)... Since these black regions probably correspond to regions that are heavily masked, perhaps this is why data split here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  19 1369 1165    0    0]\n",
      "[  58 1369 1165    0    0]\n",
      "[  97 1369 1165    0    0]\n",
      "[ 136 1369 1165    0    0]\n",
      "[4114 1369 1165    0    0]\n",
      "[4153 1369 1165    0    0]\n",
      "[4192 1369 1165    0    0]\n",
      "118932.739899\n"
     ]
    }
   ],
   "source": [
    "# what bins along this y value have unmasked = 0?\n",
    "for row in data[np.where(data[:, 1] == y)]:\n",
    "    if row[3] == 0: print row\n",
    "print np.average(data[np.where(data[:, 1] == y+39*2), 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_0_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_1_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_2_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_3_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_4_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_5_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_6_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_7_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_8_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_9_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_10_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_11_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_12_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_13_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_14_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_15_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_16_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_17_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_18_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_19_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_20_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_21_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_22_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_23_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_24_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_25_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_26_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_27_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_28_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_29_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_30_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_31_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_32_3.png' /><img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/12_33_3.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do same thing for z = 1165, since we observe this is where all the unmasked = 0 bins occur\n",
    "\n",
    "urls = [k for k,_ in groupby(\n",
    "        [get_image_url(x, y, 1165, 3) \n",
    "         for x in np.sort(np.unique(data[:, 0]))])]\n",
    "imgTags = ''.join( [\"<img style='width: 20px; margin: 0px; padding-bottom: 3px; float: left;' src='%s' />\" % str(u) \n",
    "                     for u in urls ])\n",
    "display(HTML(imgTags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that black regions do infact correspond to low unmasked.\n",
    "\n",
    "## What's unmasked = 0 look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/48_1_1.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/48_1_1.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, = np.where(data[:, 3] == 0)\n",
    "# first unmasked = 0\n",
    "args = list(data[a[0], (0, 1, 2)])\n",
    "u = get_image_url(*args)\n",
    "print u\n",
    "Image(url=u, **disp_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/2972/116_75_1.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/2972/116_75_1.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# middle one\n",
    "args = list(data[a[a.size//2], (0, 1, 2)])\n",
    "u = get_image_url(*args)\n",
    "print u\n",
    "Image(url=u, **disp_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/2972/1_1_7.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/2972/1_1_7.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zoom out middle\n",
    "args += [7]\n",
    "u = get_image_url(*args)\n",
    "print u\n",
    "Image(url=u, **disp_dim) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like regions where unmasked = 0 are corresponding to edges.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/116_132_1.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://openconnecto.me/ocp/catmaid/bock11/image/xy/4082/116_132_1.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last\n",
    "args = list(data[a[-1], (0, 1, 2)])\n",
    "u = get_image_url(*args)\n",
    "print u\n",
    "Image(url=u, **disp_dim) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be working... Another sanity check: if at resolution 0, the tiles returned contain 512 pixels, and that doubles as resolution increases, the number of pixels, at resolution r should be 512x2^r.\n",
    "Therefore resoltuion 8 should return approximately the entire cross section, since 512x2^8=131072, which is approximately the total number of pixels along the x-axis (135424). Let's test this out by grabbing the first z-layer's tile at the origin for resolution 8, i.e. the tile with url http://openconnecto.me/ocp/catmaid/bock11/image/xy/2917/0_0_8.png.\n",
    "\n",
    "<img style='width: 250px' src='http://openconnecto.me/ocp/catmaid/bock11/image/xy/2917/0_0_8.png'/>\n",
    "\n",
    "Seems to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images within context of previous analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO i.e stuff I thought I had time for this week:\n",
    "* Plot density clusterings on top of image data, will help visualize what high synaptic density areas look like, and (hopefully) help visualize the clustering results\n",
    "* Plot gradient estimates on top of image data\n",
    "* More ways to visualize data than just grabbing a single xy slice\n",
    "    * Averaging across z slices for a bin (mentioned previously)\n",
    "    * Sequentially or interactively present image data (could use embeded JavaScript/html) \n",
    "* Find a more accurate mapping from data coordinates to image (it seems ok at the moment, but I think could be better... theres lot's of empty space since origin (for the y-axis) starts well above data... additionally would like to incorporate real measurements (see Bock 2011 paper) since i mostly just focused on pixels and compared it to whatever units our data set is in)\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
